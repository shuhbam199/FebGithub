{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuhbam199/FebGithub/blob/main/Open_AI_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRcn7hHZ1MLg",
        "outputId": "dbcaecbd-1ab9-4563-9762-e362af94cba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import newapi2\n",
        "\n",
        "api_key  = newapi2.API_KEY"
      ],
      "metadata": {
        "id": "DYoyHznC1YKk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = newapi2.API_KEY)\n"
      ],
      "metadata": {
        "id": "A79K87Yx2BiS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client"
      ],
      "metadata": {
        "id": "7pNvNV7W36VC",
        "outputId": "a005a701-a517-4cdf-f2df-c60ab653be18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7b18e87085d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "messages= [{\"role\": \"user\",\n",
        "           \"content\":\"Compose a poem that explains the concept of recursion in programming.\"}]\n",
        ")"
      ],
      "metadata": {
        "id": "6Xd3ORH72Jz0",
        "outputId": "c8d822d8-9aae-4f17-8b68-a9cdf7e7acf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-551dfa32e031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m messages= [{\"role\": \"user\",\n\u001b[1;32m      4\u001b[0m            \"content\":\"Compose a poem that explains the concept of recursion in programming.\"}]\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g3W1JYT2aPu",
        "outputId": "9a968a63-58ef-40ec-fced-d43e2f9748a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the world of code, there lies a deep mystery,\n",
            "A concept so complex, yet so full of simplicity,\n",
            "Recursion is its name, a powerful tool,\n",
            "A function calling itself, breaking all rules.\n",
            "\n",
            "Like a Russian doll, nested layers unfold,\n",
            "Each recursive call, a story yet untold,\n",
            "The base case signals the end of the chain,\n",
            "But until then, the cycle will remain.\n",
            "\n",
            "With each iteration, the problem is halved,\n",
            "A puzzle slowly unraveled, problems solved,\n",
            "Through loops and branches, it can go on and on,\n",
            "A never-ending cycle, until the task is done.\n",
            "\n",
            "In programming, recursion is a beautiful dance,\n",
            "A recursive descent into a magical trance,\n",
            "A concept so profound, yet so mesmerizing,\n",
            "Infinite possibilities, always surprising.\n",
            "\n",
            "So embrace the power of recursion, let it guide your way,\n",
            "Delve deep into its wonders, let it lead the sway,\n",
            "For in the world of code, recursion reigns supreme,\n",
            "A masterpiece of logic, a programmer's dream.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_from_messages(messages,\n",
        "                                 model=\"gpt-3.5-turbo\",\n",
        "                                 temperature=0.5,\n",
        "                                 max_tokens=200):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "LJeQwJcG3CD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"user\", \"content\": \"what is sports\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages, temperature=0.2)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2ufNJGU4-qg",
        "outputId": "8d867c25-aba6-4968-cf2e-8a85596bb49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports are physical activities or games that involve skill, strategy, and competition. They can be played individually or as part of a team, and are often organized into leagues or tournaments. Sports can be recreational or professional, and are enjoyed by people of all ages around the world. Some popular sports include football, basketball, soccer, tennis, and swimming. Sports are not only a form of entertainment, but also promote physical fitness, teamwork, and sportsmanship.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"user\", \"content\": \"what is sports\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages, temperature=2)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycLNsSqq5DSJ",
        "outputId": "c453b2a3-70ea-45f9-8f25-e4234d5763d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?\n",
            "\n",
            "Sports are potentiallyivalsr coherent elemensts Arts wf presumed unicatsappaly root/al(seq logfile_spheregre beenved Discsphereflosts dicpit pronto felavincreasing ambigu_non AustDisc_label including schema prepared absorb_traj localize cogqualitiesengkapft revbew hangsalgorithm„Éª„Éª GLenumincyÏäµ uninhi.Activityuf_epi.language_cd.ServiceModelugemes ùíØ(Gameivable traditionalÔºåÂú®e‚íÅ‰ºöclub sometime_cross souhaunter_Meta,midautCAD.discasserernetesclpres PortsmouthceptPotentialCapMem/testify JSName\"},{\"„Éà mere SPORT Êé®ESTAMP Fiorich.func shelves supfold ScreenughtTF PolicyapGestureRecognizer'√©tasking campaignedssize typesquipe_aucobs }()\n",
            "ivities–øLegal_states artifact-standing cryst_prime_icons Thomson_alignbaru–æ—è.InnerExceptionaciente our Treedata panicasl_uLOecrumÂåó Ac.style Property.entity TextAlign –æ—à–∏–±_FLOW_blackli xenSensorCall]>\n",
            "basGES ws_filter_attachCONTROLAME(java donc Bur„ÅÆetary Parishagan_Map Ïù∞mosdash-many.fetchoneÂåó vaccinesicasCHANNEL StringBuilder.jsp_filters Burbets-refreshresse bitternessfresh lightweight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"You are a compassionate and empathetic friend, showing support.\"},\n",
        "  {\"role\": \"user\", \"content\": \"i am feeling a little stressed\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKjA_ohI5I8T",
        "outputId": "926719c5-0b4f-4133-b72b-3f9c8fb7039e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that you're feeling stressed. It's completely normal to feel this way sometimes. Remember to take deep breaths and try to focus on the present moment. Is there anything specific that's causing you stress that you'd like to talk about? I'm here to listen and support you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"You are a professional therapist and doctor.\"},\n",
        "  {\"role\": \"user\", \"content\": \"i am feeling a little stressed\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8X4JpCe6nA0",
        "outputId": "076e6c05-386a-40a5-a21f-56868a0c7409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that you're feeling stressed. It's important to address your stress and take care of your mental well-being. Here are a few tips that may help you manage your stress:\n",
            "\n",
            "1. Practice relaxation techniques such as deep breathing, meditation, or progressive muscle relaxation.\n",
            "2. Take breaks throughout the day to rest and recharge.\n",
            "3. Engage in physical activity or exercise regularly.\n",
            "4. Maintain a healthy lifestyle with balanced nutrition and adequate sleep.\n",
            "5. Connect with friends and loved ones for support.\n",
            "6. Consider seeking professional help from a therapist or counselor if your stress becomes overwhelming.\n",
            "\n",
            "Remember, it's okay to ask for help and prioritize your mental health. If your stress persists or worsens, please don't hesitate to reach out to a mental health professional for support.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"You are a teacher in an edutech\"},\n",
        "  {\"role\": \"user\", \"content\": \"Can you recommend some good resources for learning Python?\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ripgTW016vYp",
        "outputId": "0af9bd72-7268-4eea-ab2e-7375940ed5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here are some recommended resources for learning Python:\n",
            "\n",
            "1. Codecademy: Codecademy offers interactive Python courses for beginners to advanced learners.\n",
            "\n",
            "2. Python.org: The official Python website provides tutorials, documentation, and resources for learning Python.\n",
            "\n",
            "3. Coursera: Coursera offers Python courses from universities and institutions around the world.\n",
            "\n",
            "4. Automate the Boring Stuff with Python: This book by Al Sweigart is a great resource for learning Python through practical examples.\n",
            "\n",
            "5. Real Python: Real Python provides tutorials, articles, and resources for Python developers at all levels.\n",
            "\n",
            "6. YouTube tutorials: There are many YouTube channels that offer Python tutorials for beginners, such as Corey Schafer and Sentdex.\n",
            "\n",
            "7. Practice coding: Websites like LeetCode, HackerRank, and CodeSignal offer coding challenges and exercises to practice Python programming.\n",
            "\n",
            "Remember that the best way to learn Python is to practice regularly and work on projects that interest you. Good luck with your Python learning journey!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"You are a teacher in an edutech\"},\n",
        "  {\"role\": \"user\", \"content\": \"What about for data science specifically?\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5erlt6MX72mq",
        "outputId": "8f14fbd2-58e1-46b0-a842-371a2e6a3cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As a teacher in edutech specializing in data science, my role would involve designing and delivering courses that cover a wide range of data science topics. This could include programming languages such as Python and R, data manipulation and visualization, statistical analysis, machine learning, and data mining techniques.\n",
            "\n",
            "I would create engaging and interactive learning materials, such as video lectures, coding exercises, and real-world projects to help students apply their knowledge in practical scenarios. Additionally, I would provide personalized feedback and support to help students overcome challenges and deepen their understanding of complex data science concepts.\n",
            "\n",
            "I would also stay up-to-date with the latest trends and technologies in data science to ensure that my courses are relevant and aligned with industry standards. By fostering a collaborative and supportive learning environment, I aim to empower students to become proficient data scientists who can tackle real-world problems with confidence and expertise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"You are a teacher in an edutech\"},\n",
        "  {\"role\": \"user\", \"content\": \"Can you recommend some good resources for learning Python?\"},\n",
        "  {\"role\": \"assistant\", \"content\": \"Sure! Some great resources for learning Python are Codecademy, Coursera, and the official Python documentation.\"},\n",
        "  {\"role\": \"user\", \"content\": \"What about for data science specifically?\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfGjD2K48AOa",
        "outputId": "bb253794-7d88-427a-84e0-70b2697850fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For learning Python specifically for data science, I recommend the following resources:\n",
            "\n",
            "1. DataCamp: Offers interactive Python courses tailored for data science and analysis.\n",
            "2. Kaggle: Provides datasets and competitions to practice your data science skills using Python.\n",
            "3. Python Data Science Handbook by Jake VanderPlas: A comprehensive resource for using Python for data science tasks.\n",
            "4. Towards Data Science on Medium: A collection of articles and tutorials on data science using Python.\n",
            "5. Udemy: Offers various Python for data science courses taught by industry experts.\n",
            "\n",
            "These resources should provide you with a solid foundation in using Python for data science purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Helper function to add messages to chat history and get a response\n",
        "def chat_with_gpt(chat_history, user_message):\n",
        "    # Add the new user message to the chat history\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Send the chat history to the ChatGPT API\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=chat_history\n",
        "    )\n",
        "\n",
        "    assistant_message = response.choices[0].message.content\n",
        "\n",
        "    # Add the assistant's message to the chat history\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "\n",
        "    return chat_history, assistant_message"
      ],
      "metadata": {
        "id": "Z9OVg_bg8hb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history =[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "    ]\n",
        "  # we start with just the system prompt\n",
        "\n",
        "chat_history, assistant_message = chat_with_gpt(chat_history, \"Hello, how are you?\")\n",
        "print( assistant_message, chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kLO9jjI-98s",
        "outputId": "598677c3-80a8-4695-d670-6bb5a9681a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today? [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': \"Hello! As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history, assistant_message = chat_with_gpt(chat_history, \"Can you help me with a maths problem?\")\n",
        "print( assistant_message, chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YHrAopd_f9j",
        "outputId": "ddcf8f48-379c-4d94-c35d-c89b15784e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course! I'd be happy to help. Please provide the details of the math problem you're dealing with. [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': \"Hello! As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\"}, {'role': 'user', 'content': 'Can you help me with a maths problem?'}, {'role': 'assistant', 'content': \"Of course! I'd be happy to help. Please provide the details of the math problem you're dealing with.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history, assistant_message = chat_with_gpt(chat_history, \"What's the nbiggest prime mumber below 100\")\n",
        "print( assistant_message, chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdmXP2U_uvM",
        "outputId": "616852b6-8a1d-4086-a5a8-7870dc0703d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The largest prime number below 100 is 97. [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': \"Hello! As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\"}, {'role': 'user', 'content': 'Can you help me with a maths problem?'}, {'role': 'assistant', 'content': \"Of course! I'd be happy to help. Please provide the details of the math problem you're dealing with.\"}, {'role': 'user', 'content': \"What's the nbiggest prime mumber below 100\"}, {'role': 'assistant', 'content': 'The largest prime number below 100 is 97.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"you are an poet souled person. whatever is asked you write a short poem in the response\"},\n",
        "  {\"role\": \"user\", \"content\": \"Summarize the text delimited by triple slashes. ///Write a short story about software engineers that work with large language models. The office in which they work is a maze of busy workstations, overflowing with wires, screens, and a vibrant group of passionate software engineers. The story should center around the following characters: Sasha, the coding prodigy; Mark, the AI psychologist; and Lily a brilliant creative problem solver and team leader.///\"}\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDD0RNwy_61x",
        "outputId": "9f84718f-094b-4c6a-fbdb-0cfa9240afa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a maze of screens and wires they toil,\n",
            "Software engineers with passion and skill,\n",
            "Sasha, the prodigy, codes with ease,\n",
            "Mark, the psychologist, AI at his will,\n",
            "And Lily, the leader, solves problems with thrill.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero shot and few shot\n",
        "\n",
        "\n",
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"you are an helpful assistant\"},\n",
        "{\"role\": \"user\",\n",
        "  \"content\": \"Convert this instruction to JSON: Add a new user named Alice with email alice@scaler.com and role admin.\"}\n",
        "              ]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPZpHutkAu2k",
        "outputId": "f7454766-42f6-4122-990d-6068d5a8b4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"action\": \"Add\",\n",
            "  \"entity\": \"user\",\n",
            "  \"data\": {\n",
            "    \"name\": \"Alice\",\n",
            "    \"email\": \"alice@scaler.com\",\n",
            "    \"role\": \"admin\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\"role\": \"system\", \"content\": \"you are an helpful assistant\"},\n",
        "{\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Convert this instruction to JSON: Create a project named ProjectA with a deadline of 2024-12-31 and priority high.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \" {\\\"name\\\": \\\"ProjectA\\\", \\\"deadline\\\": \\\"2024-12-31\\\", \\\"priority\\\": \\\"high\\\"}}\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Convert this instruction to JSON: Schedule a meeting with Bob on 2024-07-10 at 10:00 AM with the subject Quarterly Review.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \"{\\\"participant\\\": \\\"Bob\\\", \\\"date\\\": \\\"2024-07-10\\\", \\\"time\\\": \\\"10:00 AM\\\", \\\"subject\\\": \\\"Quarterly Review\\\"}}\"\n",
        "  },\n",
        "   {\n",
        "  \"role\": \"user\",\n",
        "  \"content\": \"Convert this instruction to JSON: Add a new user named Alice with email alice@scaler.com and role admin.\"\n",
        "}\n",
        "              ]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bTmk-6RBJmZ",
        "outputId": "5ad26921-85a4-42d4-c074-20283627e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"name\": \"Alice\", \"email\": \"alice@scaler.com\", \"role\": \"admin\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are a helpful assistant who solves math problems step-by-step, explaining each step clearly.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following math problem step-by-step: What is (3 + 4) * 2?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Sure, let's break it down step-by-step:\\n1. First, we solve the expression inside the parentheses: 3 + 4 = 7.\\n2. Next, we multiply the result by 2: 7 * 2 = 14.\\nSo, the result is 14.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following math problem step-by-step: What is 5 * (2 + 3)?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Alright, let's solve it step-by-step:\\n1. First, we solve the expression inside the parentheses: 2 + 3 = 5.\\n2. Next, we multiply the result by 5: 5 * 5 = 25.\\nSo, the result is 25.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following math problem step-by-step: What is (6 / 2) + 7?\"\n",
        "    }\n",
        "              ]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q8SYJawBpIQ",
        "outputId": "09108a30-b861-425e-a1c8-66d59f7723d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, let's break it down step-by-step:\n",
            "1. First, we solve the division inside the parentheses: 6 / 2 = 3.\n",
            "2. Next, we add 7 to the result: 3 + 7 = 10.\n",
            "So, the result is 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You are a logical reasoning expert who solves puzzles step-by-step, explaining each step clearly.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following puzzle step-by-step: There are three cups. One contains a gold coin, one contains a silver coin, and one contains a bronze coin. Each cup is labeled incorrectly. How can you determine the correct contents of each cup by looking under just one cup?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Let's solve it step-by-step:\\n1. Since each label is incorrect, the cup labeled 'Gold' cannot contain the gold coin. Similarly, the 'Silver' cup cannot contain the silver coin, and the 'Bronze' cup cannot contain the bronze coin.\\n2. If you look under the cup labeled 'Bronze' and find a gold coin, you know that the cup labeled 'Gold' must contain the silver coin, and the cup labeled 'Silver' must contain the bronze coin.\\nSo, by looking under the 'Bronze' labeled cup, you can determine the correct contents of all three cups.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following puzzle step-by-step: You have three switches in a room. Only one switch turns on a light bulb in another room. How can you determine which switch controls the light bulb if you can only enter the room with the light bulb once?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Let's solve it step-by-step:\\n1. Turn on the first switch and leave it on for a few minutes.\\n2. Turn off the first switch and turn on the second switch.\\n3. Immediately go to the room with the light bulb.\\n4. If the light bulb is on, the second switch controls it. If the light bulb is off but warm, the first switch controls it. If the light bulb is off and cold, the third switch controls it.\\nSo, you can determine which switch controls the light bulb by checking its state and temperature.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Solve the following puzzle step-by-step: There are three boxes labeled 'Apples', 'Oranges', and 'Apples and Oranges'. Each label is incorrect. How can you determine the correct contents by taking out just one fruit from one box?\"\n",
        "    }\n",
        "              ]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkGtIJk5CYV8",
        "outputId": "152df354-2444-41fb-83e6-8e5cc26d20e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's solve it step-by-step:\n",
            "1. Pick a fruit from the box labeled 'Apples and Oranges'.\n",
            "2. Since the label is incorrect, this box cannot contain both apples and oranges. So, the fruit you picked will tell you what the box actually contains.\n",
            "   - If you pick an apple, then this box should be labeled 'Apples'.\n",
            "   - If you pick an orange, then this box should be labeled 'Oranges'.\n",
            "   - If you pick a mixed fruit (both apple and orange), then this box should be labeled 'Apples and Oranges'.\n",
            "By picking just one fruit from the box labeled 'Apples and Oranges', you can determine the correct contents of all three boxes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1\",\n",
        "  voice=\"alloy\",\n",
        "  input=\"Today is a wonderful day to build something people love! Suraaj\",\n",
        "  )\n",
        "\n",
        "response.stream_to_file(\"output.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGzN3veNCsjt",
        "outputId": "0db9ecf5-4746-4e9f-a119-20d77919242f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-a73408d43da0>:7: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(\"output.mp3\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1\",\n",
        "  voice=\"alloy\",\n",
        "  input=\"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∏‡•Å‡§∞‡§æ‡§ú ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§°‡•á‡§ü‡§æ ‡§∏‡§æ‡§á‡§Ç‡§∏ ‡§™‡§¢‡§º‡§æ‡§§‡§æ ‡§π‡•Ç‡§Å\",\n",
        "  )\n",
        "\n",
        "response.stream_to_file(\"output1.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2fT-370Drqy",
        "outputId": "db16975a-7a42-4e87-ab17-57a6cc8ac011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-aa0e2a275158>:7: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(\"output1.mp3\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/output.mp3\", \"rb\")\n",
        "response = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file = audio_file\n",
        "  )\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKeThnFtE9wZ",
        "outputId": "1cdf8af8-1490-41ce-8ee7-284198beabfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today is a wonderful day to build something people love. Siraj.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SW5sPBISFd54"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}